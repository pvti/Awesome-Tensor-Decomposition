# [![Awesome](https://awesome.re/badge.svg)](https://awesome.re) Tensor Decomposition 
A curated list of tensor decomposition resources for *network compression*.

## :clipboard: Research Papers
| Title                                                        | Code      | Venue      | Year |
| ------------------------------------------------------------ | ----------| ---------- | ---- |
| [A Practical Approach for Employing Tensor Train Decomposition in Edge Devices](https://link.springer.com/article/10.1007/s10766-024-00762-3) || International Journal of Parallel Programming | 2024 |
| [Structure-Preserving Network Compression Via Low-Rank Induced Training Through Linear Layers Composition](https://arxiv.org/abs/2405.03089) || Arxiv | 2024 |
| [LoRETTA: Low-Rank Economic Tensor-Train Adaptation for Ultra-Low-Parameter Fine-Tuning of Large Language Models](https://arxiv.org/abs/2402.11417) |[![GitHub Repo stars](https://img.shields.io/github/stars/yifanycc/loretta)](https://github.com/yifanycc/loretta)| NAACL | 2024 |
| [CoMERA: Computing- and Memory-Efficient Training via Rank-Adaptive Tensor Optimization](https://arxiv.org/abs/2405.14377) || Arxiv | 2024 |
| [FLoRA: Low-Rank Core Space for N-dimension](https://arxiv.org/abs/2405.14739) |[![GitHub Repo stars](https://img.shields.io/github/stars/SJTU-DeepVisionLab/FLoRA)](https://github.com/SJTU-DeepVisionLab/FLoRA)| Arxiv | 2024 |
| [Reduced storage direct tensor ring decomposition for convolutional neural networks compression](https://arxiv.org/abs/2405.10802) |[![GitHub Repo stars](https://img.shields.io/github/stars/mateuszgabor/rsdtr_compression)](https://github.com/mateuszgabor/rsdtr_compression)| Arxiv | 2024 |
| [Federated Learning Using Coupled Tensor Train Decomposition](https://arxiv.org/abs/2403.02898) | | Arxiv | 2024 |
| [Neural Network Compression Based on Tensor Ring Decomposition](https://ieeexplore.ieee.org/abstract/document/10510501) | | TNNLS | 2024 |
| [Enhanced network compression through tensor decompositions and pruning](https://hal.science/hal-04475167v1) |[![GitHub Repo stars](https://img.shields.io/github/stars/pvtien96/NORTON)](https://github.com/pvtien96/NORTON)| TNNLS | 2024 |
| [Enhancing GAN Performance Through Neural Architecture Search and Tensor Decomposition](https://ieeexplore.ieee.org/document/10446488) |[![GitHub Repo stars](https://img.shields.io/github/stars/PrasannaPulakurthi/MMD-AdversarialNAS)](https://github.com/PrasannaPulakurthi/MMD-AdversarialNAS)| ICASSP | 2024 |
| [Deep Convolutional Neural Network Compression Method: Tensor Ring Decomposition with Variational Bayesian Approach](https://link.springer.com/article/10.1007/s11063-024-11465-8) || Neural Processing Letters | 2024 |
| [Deep Learning Model Compression With Rank Reduction in Tensor Decomposition](https://ieeexplore.ieee.org/abstract/document/10321737) || TNNLS | 2023 |
| [How Informative is the Approximation Error from Tensor Decomposition for Neural Network Compression?](https://arxiv.org/abs/2305.05318) || ICLR | 2023 |
| [Compressing convolutional neural networks with hierarchical Tucker-2 decomposition](https://www.sciencedirect.com/science/article/pii/S156849462200905X) |[![GitHub Repo stars](https://img.shields.io/github/stars/mateuszgabor/ht2)](https://github.com/mateuszgabor/ht2)| Applied Soft Computing | 2023 |
| [Tensor shape search for efficient compression of tensorized data and neural networks](https://www.sciencedirect.com/science/article/pii/S1568494623010050) || Applied Soft Computing | 2023 |
| [An effective low-rank compression with a joint rank selection followed by a compression-friendly training](https://www.sciencedirect.com/science/article/pii/S0893608023000242) || Neural Networks | 2023 |
| [Joint matrix decomposition for deep convolutional neural networks compression](https://www.sciencedirect.com/science/article/pii/S0925231222012887) || Neurocomputing | 2023 |
| [Training Acceleration of Low-Rank Decomposed Networks using Sequential Freezing and Rank Quantization](https://arxiv.org/abs/2309.03824) || Arxiv | 2023 |
| [HODEC: Towards Efficient High-Order DEcomposed Convolutional Neural Networks](https://ieeexplore.ieee.org/document/9879408) || CVPR | 2022 |
| [Convolutional Neural Network Compression through Generalized Kronecker Product Decomposition](https://ojs.aaai.org/index.php/AAAI/article/view/19958) || AAAI | 2022 |
| [Towards Compact Neural Networks via End-to-End Training: A Bayesian Tensor Approach with Automatic Rank Determination](https://arxiv.org/abs/2010.08689) |[![GitHub Repo stars](https://img.shields.io/github/stars/colehawkins/bayesian-tensor-rank-determination)](https://github.com/colehawkins/bayesian-tensor-rank-determination)| SIMODS | 2022 |
| [Deep neural network compression by Tucker decomposition with nonlinear response](https://www.sciencedirect.com/science/article/pii/S0950705122000326) || Knowledge-Based Systems | 2022 |
| [Nested compression of convolutional neural networks with Tucker-2 decomposition](https://ieeexplore.ieee.org/abstract/document/9892959) || IJCNN | 2022 |
| [A Design Space Exploration Methodology for Enabling Tensor Train Decomposition in Edge Devices](https://link.springer.com/chapter/10.1007/978-3-031-15074-6_11) || SAMOS | 2022 |
| [Compressing Neural Networks: Towards Determining the Optimal Layer-wise Decomposition](https://arxiv.org/abs/2107.11442) |[![GitHub Repo stars](https://img.shields.io/github/stars/lucaslie/torchprune)](https://github.com/lucaslie/torchprune)| NeurIPS | 2021 |
| [Towards Efficient Tensor Decomposition-Based DNN Model Compression with Optimization Framework](https://ieeexplore.ieee.org/document/9577813) || CVPR | 2021 |
| [Deep Convolutional Neural Network Compression via Coupled Tensor Decomposition](https://ieeexplore.ieee.org/document/9261106) || JSTSP | 2021 |
| [Low-Rank Compression of Neural Nets: Learning the Rank of Each Layer](https://ieeexplore.ieee.org/document/9157223) |[![GitHub Repo stars](https://img.shields.io/github/stars/UCMerced-ML/LC-model-compression)](https://github.com/UCMerced-ML/LC-model-compression)| CVPR | 2020 |
| [Learning Low-rank Deep Neural Networks via Singular Vector Orthogonality Regularization and Singular Value Sparsification](https://arxiv.org/abs/2004.09031) |[![GitHub Repo stars](https://img.shields.io/github/stars/yanghr/SVD_Prune_EDLCV)](https://github.com/yanghr/SVD_Prune_EDLCV)| CVPRW | 2020 |
| [ADA-Tucker: Compressing deep neural networks via adaptive dimension adjustment tucker decomposition](https://www.sciencedirect.com/science/article/pii/S0893608018303010) || Neural Networks | 2019 |
| [Learning Filter Basis for Convolutional Neural Network Compression](https://arxiv.org/abs/1908.08932) |[![GitHub Repo stars](https://img.shields.io/github/stars/ofsoundof/learning_filter_basis)](https://github.com/ofsoundof/learning_filter_basis)| ICCV | 2019 |
| [Compressing Deep Models using Multi Tensor Train Decomposition](https://ieeexplore.ieee.org/document/9074612) || ICCAIS | 2019 |
| [Compressing Fully Connected Layers using Kronecker Tensor Decomposition](https://ieeexplore.ieee.org/document/8962432) || ICCSNT | 2019 |
| [Accelerating Very Deep Convolutional Networks for Classification and Detection](https://arxiv.org/abs/1505.06798) || TPAMI | 2016 |
| [Compression of Deep Convolutional Neural Networks for Fast and Low Power Mobile Applications](https://arxiv.org/abs/1511.06530) || ICLR | 2016 |
| [Speeding-up Convolutional Neural Networks Using Fine-tuned CP-Decomposition](https://arxiv.org/abs/1412.6553) || ICLR | 2015 |
| [Speeding up Convolutional Neural Networks with Low Rank Expansions](https://arxiv.org/abs/1405.3866) || Arxiv | 2014 |

## :books: Surveys
| Title                                                        | Venue      | Year |
| ------------------------------------------------------------ | ---------- | ---- |
| [Low Rank Optimization for Efficient Deep Learning: Making A Balance between Compact Architecture and Fast Training](https://arxiv.org/abs/2303.13635)| Arxiv | 2023 |
| [Tensor Networks Meet Neural Networks: A Survey and Future Perspectives](https://arxiv.org/abs/2302.09019) [![GitHub Repo stars](https://img.shields.io/github/stars/tnbar/awesome-tensorial-neural-networks)](https://github.com/tnbar/awesome-tensorial-neural-networks)| Arxiv | 2023 |
| [Tensor Decomposition for Signal Processing and Machine Learning](https://ieeexplore.ieee.org/abstract/document/7891546) | IEEE Transactions on Signal Processing | 2017 |
| [The Higher-Order Singular Value Decomposition: Theory and an Application](https://ieeexplore.ieee.org/document/5447070) | IEEE Signal Processing Magazine | 2010 |
| [Tensor Decompositions and Applications](https://epubs.siam.org/doi/10.1137/07070111X) | SIAM Review | 2009 |

## :blue_book: Miscellaneous
| Title                                                        | Venue      | Year |
| ------------------------------------------------------------ | ---------- | ---- |
| [Nuclear Norm of Higher-Order Tensors](https://arxiv.org/abs/1410.6072) | Mathematics of Computation | 2018 |

## :computer: Repositories
- [TensorLy](https://github.com/tensorly/tensorly) [![GitHub Repo stars](https://img.shields.io/github/stars/tensorly/tensorly)](https://github.com/tensorly/tensorly)
- [PyTorch Tensor Decompositions](https://jacobgil.github.io/deeplearning/tensor-decompositions-deep-learning)[![GitHub Repo stars](https://img.shields.io/github/stars/jacobgil/pytorch-tensor-decompositions)](https://github.com/jacobgil/pytorch-tensor-decompositions)
- [CNN_compression_with_Tensor_Decomposition](https://github.com/K0EKJE/CNN_compression_with_Tensor_Decomposition)[![GitHub Repo stars](https://img.shields.io/github/stars/K0EKJE/CNN_compression_with_Tensor_Decomposition)](https://github.com/K0EKJE/CNN_compression_with_Tensor_Decomposition)
- [Tensor methods in Python with TensorLy](https://github.com/JeanKossaifi/tensorly-notebooks)[![GitHub Repo stars](https://img.shields.io/github/stars/JeanKossaifi/tensorly-notebooks)](https://github.com/JeanKossaifi/tensorly-notebooks)
- [TensorKrowch: Smooth integration of tensor networks in machine learning](https://arxiv.org/abs/2306.08595)[![GitHub Repo stars](https://img.shields.io/github/stars/joserapa98/tensorkrowch)](https://github.com/joserapa98/tensorkrowch)
